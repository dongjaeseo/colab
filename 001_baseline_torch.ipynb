{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "001_baseline_torch.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNJ+fkt4M7QbUzBJ81g/dmI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dongjaeseo/colab/blob/main/001_baseline_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGQC1TbutzZG"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "import os\r\n",
        "from typing import Tuple, Sequence, Callable\r\n",
        "import csv\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from PIL import Image\r\n",
        "import torch\r\n",
        "import torch.optim as optim\r\n",
        "from torch import nn, Tensor\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "!pip install torchinfo\r\n",
        "from torchinfo import summary\r\n",
        "\r\n",
        "from torchvision import transforms\r\n",
        "from torchvision.models import resnet50\r\n",
        "\r\n",
        "class MnistDataset(Dataset):\r\n",
        "    def __init__(\r\n",
        "        self,\r\n",
        "        dir: os.PathLike,\r\n",
        "        image_ids: os.PathLike,\r\n",
        "        transforms: Sequence[Callable]\r\n",
        "    ) -> None:\r\n",
        "        self.dir = dir\r\n",
        "        self.transforms = transforms\r\n",
        "\r\n",
        "        self.labels = {}\r\n",
        "        with open(image_ids, 'r') as f:\r\n",
        "            reader = csv.reader(f)\r\n",
        "            next(reader)\r\n",
        "            for row in reader:\r\n",
        "                self.labels[int(row[0])] = list(map(int, row[1:]))\r\n",
        "\r\n",
        "        self.image_ids = list(self.labels.keys())\r\n",
        "\r\n",
        "    def __len__(self) -> int:\r\n",
        "        return len(self.image_ids)\r\n",
        "\r\n",
        "    def __getitem__(self, index: int) -> Tuple[Tensor]:\r\n",
        "        image_id = self.image_ids[index]\r\n",
        "        image = Image.open(\r\n",
        "            os.path.join(\r\n",
        "                self.dir, f'{str(image_id).zfill(5)}.png')).convert('RGB')\r\n",
        "        target = np.array(self.labels.get(image_id)).astype(np.float32)\r\n",
        "\r\n",
        "        if self.transforms is not None:\r\n",
        "            image = self.transforms(image)\r\n",
        "\r\n",
        "        return image, target\r\n",
        "\r\n",
        "transforms_train = transforms.Compose([\r\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\r\n",
        "    transforms.RandomVerticalFlip(p=0.5),\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize(\r\n",
        "        [0.485, 0.456, 0.406],\r\n",
        "        [0.229, 0.224, 0.225]\r\n",
        "    )\r\n",
        "])\r\n",
        "\r\n",
        "transforms_test = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize(\r\n",
        "        [0.485, 0.456, 0.406],\r\n",
        "        [0.229, 0.224, 0.225]\r\n",
        "    )\r\n",
        "])\r\n",
        "\r\n",
        "trainset = MnistDataset('/content/drive/MyDrive/mnist/dirty_mnist_2nd', '/content/drive/MyDrive/mnist/dirty_mnist_2nd_answer.csv', transforms_train)\r\n",
        "testset = MnistDataset('/content/drive/MyDrive/mnist/test_dirty_mnist_2nd', '/content/drive/MyDrive/mnist/dirty_mnist_2nd_answer.csv', transforms_test)\r\n",
        "\r\n",
        "train_loader = DataLoader(trainset, batch_size=256, num_workers=8)\r\n",
        "test_loader = DataLoader(testset, batch_size=32, num_workers=4)\r\n",
        "\r\n",
        "class MnistModel(nn.Module):\r\n",
        "    def __init__(self) -> None:\r\n",
        "        super().__init__()\r\n",
        "        self.resnet = resnet50(pretrained=True)\r\n",
        "        self.classifier = nn.Linear(1000, 26)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.resnet(x)\r\n",
        "        x = self.classifier(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "device = torch.device('cuda')\r\n",
        "model = MnistModel().to(device)\r\n",
        "# print(summary(model, input_size=(1, 3, 256, 256), verbose=0))\r\n",
        "\r\n",
        "# 실행 하는 곳이 메인인 경우\r\n",
        "if __name__ == '__main__':\r\n",
        "    \r\n",
        "    # 옵티마이저와 멀티라벨소프트 마진 로스를 사용함\r\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\r\n",
        "    criterion = nn.MultiLabelSoftMarginLoss()\r\n",
        "\r\n",
        "    # 에포치 10주고 모델을 트레인으로 변환\r\n",
        "    num_epochs = 40\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    # 에포치 만큼 반복\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "            # 배치 사이즈 만큼 스탭을 진행함\r\n",
        "            for i, (images, targets) in enumerate(train_loader):\r\n",
        "\r\n",
        "                # 미분 값 초기화\r\n",
        "                optimizer.zero_grad()\r\n",
        "                # 데이터셋을 프로세스에 입력함\r\n",
        "                images = images.to(device)\r\n",
        "                targets = targets.to(device)\r\n",
        "                # 모델에 인풋을 넣고 아웃풋을 출력함\r\n",
        "                outputs = model(images)\r\n",
        "                # 로스를 확인함\r\n",
        "                loss = criterion(outputs, targets)\r\n",
        "\r\n",
        "                # 로스 역전파\r\n",
        "                loss.backward()\r\n",
        "                # 매개변수 갱신함\r\n",
        "                optimizer.step()\r\n",
        "            \r\n",
        "                # 10에포치 마다 로스와 액큐러시를 출력함\r\n",
        "                if (i+1) % 10 == 0:\r\n",
        "                    outputs = outputs > 0.5\r\n",
        "                    acc = (outputs == targets).float().mean()\r\n",
        "                    print(f'{epoch}: {loss.item():.5f}, {acc.item():.5f}')\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "\r\n",
        "    # 평가 폴더를 열음\r\n",
        "    submit = pd.read_csv('/content/drive/MyDrive/mnist/sample_submission.csv')\r\n",
        "\r\n",
        "    # 이벨류 모드로 전환\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # 베치사이즈는 테스트로더 베치사이즈\r\n",
        "    batch_size = test_loader.batch_size\r\n",
        "    # 인덱스 0부터 시작\r\n",
        "    batch_index = 0\r\n",
        "    # 이벨류 모드를 테스트 셋으로 진행하고 파일에 입력함\r\n",
        "    for i, (images, targets) in enumerate(test_loader):\r\n",
        "        images = images.to(device)\r\n",
        "        targets = targets.to(device)\r\n",
        "        outputs = model(images)\r\n",
        "        outputs = outputs > 0.5\r\n",
        "        batch_index = i * batch_size\r\n",
        "        submit.iloc[batch_index:batch_index+batch_size, 1:] = \\\r\n",
        "            outputs.long().squeeze(0).detach().cpu().numpy()\r\n",
        "\r\n",
        "    # 저장함\r\n",
        "    submit.to_csv('/content/drive/MyDrive/mnist/submit0223.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yphDUJEB_cWJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}