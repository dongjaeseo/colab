{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "003_efficientnet-b4.ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPEDBrB6p+aSSGTXQRGgIOp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dongjaeseo/colab/blob/main/003_efficientnet_b4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvg-PZPOMa8P"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "import torch\r\n",
        "import glob\r\n",
        "import os\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import pandas as pd\r\n",
        "import cv2\r\n",
        "from tqdm import tqdm\r\n",
        "import numpy as np\r\n",
        "from torchvision import transforms\r\n",
        "import torchvision.models as models\r\n",
        "import torch.nn as nn\r\n",
        "from torch.nn import functional as F\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "import time\r\n",
        "# !pip install git+https://github.com/cmpark0126/pytorch-polynomial-lr-decay.git\r\n",
        "from efficientnet_pytorch import EfficientNet\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch_poly_lr_decay import PolynomialLRDecay\r\n",
        "import random\r\n",
        "\r\n",
        "# 병렬로 사용할 수\r\n",
        "torch.set_num_threads(1)\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "# /content/drive/MyDrive/mnist/dirty_mnist_2nd_answer.csv\r\n",
        "# labels 에는 답\r\n",
        "labels_df = pd.read_csv('/content/drive/MyDrive/mnist/dirty_mnist_2nd_answer.csv)[:]\r\n",
        "imgs_dir = np.array(sorted(glob.glob('/content/drive/MyDrive/mnist/dirty_mnist_2nd/*')))[:]\r\n",
        "labels = np.array(labels_df.values[:,1:])\r\n",
        "\r\n",
        "test_imgs_dir = np.array(sorted(glob.glob('/content/drive/MyDrive/mnist/test_dirty_mnist_2nd/*')))\r\n",
        "\r\n",
        "imgs=[]\r\n",
        "for path in tqdm(imgs_dir[:]):\r\n",
        "    img=cv2.imread(path, cv2.IMREAD_COLOR)\r\n",
        "    imgs.append(img)\r\n",
        "imgs=np.array(imgs)\r\n",
        "\r\n",
        "# 저장소에서 load\r\n",
        "class MnistDataset_v1(Dataset):\r\n",
        "    def __init__(self, imgs_dir=None, labels=None, transform=None, train=True):\r\n",
        "        self.imgs_dir = imgs_dir\r\n",
        "        self.labels = labels\r\n",
        "        self.transform = transform\r\n",
        "        self.train = train\r\n",
        "        pass\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        # 데이터 총 샘플 수\r\n",
        "        return len(self.imgs)\r\n",
        "    \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        # 1개 샘플 get\r\n",
        "        img = cv2.imread(self.imgs_dir[idx], cv2.IMREAD_COLOR)\r\n",
        "        img = self.transform(img)\r\n",
        "        if self.train==True:\r\n",
        "            label = self.labels[idx]\r\n",
        "            return img, label\r\n",
        "        else:\r\n",
        "            return img\r\n",
        "        \r\n",
        "        pass\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "# 메모리에서 load\r\n",
        "class MnistDataset_v2(Dataset):\r\n",
        "    def __init__(self, imgs=None, labels=None, transform=None, train=True):\r\n",
        "        self.imgs = imgs\r\n",
        "        self.labels = labels\r\n",
        "        self.transform = transform\r\n",
        "        self.train=train\r\n",
        "        pass\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        # 데이터 총 샘플 수\r\n",
        "        return len(self.imgs)\r\n",
        "    \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        # 1개 샘플 get1\r\n",
        "        img = self.imgs[idx]\r\n",
        "        img = self.transform(img)\r\n",
        "        \r\n",
        "        if self.train==True:\r\n",
        "            label = self.labels[idx]\r\n",
        "            return img, label\r\n",
        "        else:\r\n",
        "            return img\r\n",
        "\r\n",
        "# https://dacon.io/competitions/official/235697/codeshare/2363?page=1&dtype=recent&ptype=pub\r\n",
        "def seed_everything(seed: int = 42):\r\n",
        "    random.seed(seed)\r\n",
        "    np.random.seed(seed)\r\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\r\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\r\n",
        "    torch.backends.cudnn.benchmark = True  \r\n",
        "\r\n",
        "# EfficientNet -b0(pretrained)\r\n",
        "# MultiLabel output\r\n",
        "\r\n",
        "class EfficientNet_MultiLabel(nn.Module):\r\n",
        "    def __init__(self, in_channels):\r\n",
        "        super(EfficientNet_MultiLabel, self).__init__()\r\n",
        "        self.network = EfficientNet.from_pretrained('efficientnet-b4', in_channels=in_channels)\r\n",
        "        self.output_layer = nn.Linear(1000, 26)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.relu(self.network(x))\r\n",
        "        x = torch.sigmoid(self.output_layer(x))\r\n",
        "        return x\r\n",
        "\r\n",
        "# 해당 코드에서는 1fold만 실행\r\n",
        "\r\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\r\n",
        "folds=[]\r\n",
        "for train_idx, valid_idx in kf.split(imgs):\r\n",
        "    folds.append((train_idx, valid_idx))\r\n",
        "\r\n",
        "### seed_everything(42)\r\n",
        "\r\n",
        "# 5개의 fold 모두 실행하려면 for문을 5번 돌리면 됩니다.\r\n",
        "for fold in range(5):\r\n",
        "    model = EfficientNet_MultiLabel(in_channels=3).to(device)\r\n",
        "#     model = nn.DataParallel(model)\r\n",
        "    train_idx = folds[fold][0]\r\n",
        "    valid_idx = folds[fold][1]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    train_transform = transforms.Compose([\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        transforms.RandomVerticalFlip()\r\n",
        "        ])\r\n",
        "    valid_transform = transforms.Compose([\r\n",
        "        transforms.ToTensor(),\r\n",
        "        ])\r\n",
        "\r\n",
        "\r\n",
        "    epochs=50\r\n",
        "    batch_size=47         # 자신의 VRAM에 맞게 조절해야 OOM을 피할 수 있습니다.\r\n",
        "    \r\n",
        "    \r\n",
        "    \r\n",
        "    # Data Loader\r\n",
        "    train_dataset = MnistDataset_v2(imgs = imgs[train_idx], labels=labels[train_idx], transform=train_transform)\r\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\r\n",
        "\r\n",
        "    valid_dataset = MnistDataset_v2(imgs = imgs[valid_idx], labels = labels[valid_idx], transform=valid_transform)\r\n",
        "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False)       \r\n",
        "    \r\n",
        "    \r\n",
        "    # optimizer\r\n",
        "    # polynomial optimizer를 사용합니다.\r\n",
        "    # \r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\r\n",
        "    decay_steps = (len(train_dataset)//batch_size)*epochs\r\n",
        "    scheduler_poly_lr_decay = PolynomialLRDecay(optimizer, max_decay_steps=decay_steps, end_learning_rate=1e-6, power=0.9)\r\n",
        "\r\n",
        "    criterion = torch.nn.BCELoss()\r\n",
        "    \r\n",
        "    \r\n",
        "    epoch_accuracy = []\r\n",
        "    valid_accuracy = []\r\n",
        "    valid_losses=[]\r\n",
        "    valid_best_accuracy=0\r\n",
        "    for epoch in range(epochs):\r\n",
        "        model.train()\r\n",
        "        batch_accuracy_list = []\r\n",
        "        batch_loss_list = []\r\n",
        "        start=time.time()\r\n",
        "        for n, (X, y) in enumerate((train_loader)):\r\n",
        "            X = torch.tensor(X, device=device, dtype=torch.float32)\r\n",
        "            y = torch.tensor(y, device=device, dtype=torch.float32)\r\n",
        "            y_hat = model(X)\r\n",
        "            \r\n",
        "            \r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss = criterion(y_hat, y)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            scheduler_poly_lr_decay.step()\r\n",
        "\r\n",
        "            \r\n",
        "            y_hat  = y_hat.cpu().detach().numpy()\r\n",
        "            y_hat = y_hat>0.5\r\n",
        "            y = y.cpu().detach().numpy()\r\n",
        "\r\n",
        "            batch_accuracy = (y_hat == y).mean()\r\n",
        "            batch_accuracy_list.append(batch_accuracy)\r\n",
        "            batch_loss_list.append(loss.item())\r\n",
        "\r\n",
        "        model.eval()\r\n",
        "        valid_batch_accuracy=[]\r\n",
        "        valid_batch_loss = []\r\n",
        "        with torch.no_grad():\r\n",
        "            for n_valid, (X_valid, y_valid) in enumerate((valid_loader)):\r\n",
        "                X_valid = torch.tensor(X_valid, device=device)#, dtype=torch.float32)\r\n",
        "                y_valid = torch.tensor(y_valid, device=device, dtype=torch.float32)\r\n",
        "                y_valid_hat = model(X_valid)\r\n",
        "                \r\n",
        "                valid_loss = criterion(y_valid_hat, y_valid).item()\r\n",
        "                \r\n",
        "                y_valid_hat = y_valid_hat.cpu().detach().numpy()>0.5\r\n",
        "                \r\n",
        "                \r\n",
        "                valid_batch_loss.append(valid_loss)\r\n",
        "                valid_batch_accuracy.append((y_valid_hat == y_valid.cpu().detach().numpy()).mean())\r\n",
        "                \r\n",
        "            valid_losses.append(np.mean(valid_batch_loss))\r\n",
        "            valid_accuracy.append(np.mean(valid_batch_accuracy))\r\n",
        "            \r\n",
        "        if np.mean(valid_batch_accuracy)>valid_best_accuracy:\r\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/dacon/model/EfficientNetB4-fold{}.pt'.format(fold))\r\n",
        "            valid_best_accuracy = np.mean(valid_batch_accuracy)\r\n",
        "        print('fold : {}\\tepoch : {:02d}\\ttrain_accuracy / loss : {:.5f} / {:.5f}\\tvalid_accuracy / loss : {:.5f} / {:.5f}\\ttime : {:.0f}'.format(fold+1, epoch+1,\r\n",
        "                                                                                                                                              np.mean(batch_accuracy_list),\r\n",
        "                                                                                                                                              np.mean(batch_loss_list),\r\n",
        "                                                                                                                                              np.mean(valid_batch_accuracy), \r\n",
        "                                                                                                                                              np.mean(valid_batch_loss),\r\n",
        "                                                                                                                                              time.time()-start))\r\n",
        "            \r\n",
        "test_imgs=[]\r\n",
        "for path in tqdm(test_imgs_dir):\r\n",
        "    test_img=cv2.imread(path, cv2.IMREAD_COLOR)\r\n",
        "    test_imgs.append(test_img)\r\n",
        "test_imgs=np.array(test_imgs)\r\n",
        "\r\n",
        "test_transform = transforms.Compose([\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        transforms.RandomVerticalFlip()\r\n",
        "        ])\r\n",
        "\r\n",
        "submission = pd.read_csv('/content/drive/MyDrive/dacon/sample_submission.csv')\r\n",
        "for i in range(5):\r\n",
        "    with torch.no_grad():\r\n",
        "        for fold in range(5):\r\n",
        "            model = EfficientNet_MultiLabel(in_channels=3).to(device)\r\n",
        "            model.load_state_dict(torch.load('/content/drive/MyDrive/dacon/model/EfficientNetB4-fold{}.pt'.format(fold)))\r\n",
        "            model.eval()\r\n",
        "\r\n",
        "            test_dataset = MnistDataset_v2(imgs = test_imgs, transform=test_transform, train=False)\r\n",
        "            test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\r\n",
        "\r\n",
        "            for n, X_test in enumerate(tqdm(test_loader)):\r\n",
        "                X_test = torch.tensor(X_test, device=device, dtype=torch.float32)\r\n",
        "                with torch.no_grad():\r\n",
        "                    model.eval()\r\n",
        "                    pred_test = model(X_test).cpu().detach().numpy()\r\n",
        "                    submission.iloc[n*32:(n+1)*32,1:] += pred_test\r\n",
        "            \r\n",
        "submission.iloc[:,1:] = np.where(submission.values[:,1:]>=2.5, 1,0)\r\n",
        "\r\n",
        "submission.to_csv('/content/drive/MyDrive/dacon/EfficientNetB4-fold5.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}